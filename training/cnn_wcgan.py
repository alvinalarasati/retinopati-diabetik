# -*- coding: utf-8 -*-
"""CNN WCGAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1akDF901WS9QD4FcbAip7JQtlGWznJCyh
"""

import os
import cv2
import numpy as np
from tqdm import tqdm
from skimage.filters import frangi
from skimage.morphology import remove_small_objects
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix
import tensorflow as tf
from tensorflow.keras.layers import (Input, Dense, Reshape, Flatten, Embedding,
                                     BatchNormalization, LeakyReLU, Concatenate,
                                     Conv2D, Conv2DTranspose)
from tensorflow.keras.models import Model
from google.colab import drive

from google.colab import drive
drive.mount('/content/drive')

drive.mount('/content/drive', force_remount=True)

"""# DATA"""

# Define paths and parameters
RAW_DIR = '/content/drive/MyDrive/SKRIPSI/dataretina/data'
OUTPUT_DIR = './dataset_clinical_stages'
MODEL_PATH = './weights/rd_feature_model.keras'
IMG_SIZE = (128, 128)
BATCH_SIZE = 16

# Create output directories
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs('./weights', exist_ok=True)

# Load and inspect dataset with image display
image_files = [os.path.join(RAW_DIR, fname) for fname in os.listdir(RAW_DIR)
               if fname.lower().endswith(('.jpg', '.png', '.jpeg'))]
print(f"Total number of images found: {len(image_files)}")
print("Sample filenames and images in RAW_DIR:")
fig, axes = plt.subplots(1, 5, figsize=(15, 3))  # Create a row of 5 subplots
for i, fname in enumerate(image_files[:5]):  # Process first 5 files
    img = cv2.imread(fname)
    if img is not None:
        img = cv2.resize(img, IMG_SIZE)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct display
        axes[i].imshow(img)
        axes[i].set_title(f"{i+1}. {os.path.basename(fname)}")
        axes[i].axis('off')
plt.tight_layout()
plt.show()

# Preprocessing function
def preprocess_image(img_path):
    img = cv2.imread(img_path)
    if img is None:
        return None
    img = cv2.resize(img, IMG_SIZE)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = img / 255.0
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    img = clahe.apply(cv2.cvtColor(img.astype(np.uint8) * 255, cv2.COLOR_RGB2GRAY))
    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) / 255.0
    return img

# Preprocess all images
preprocessed_images = []
valid_image_files = []
for img_path in tqdm(image_files, total=len(image_files)):
    img = preprocess_image(img_path)
    if img is not None:
        preprocessed_images.append(img)
        valid_image_files.append(img_path)

preprocessed_images = np.array(preprocessed_images)
print(f"Preprocessed images shape: {preprocessed_images.shape}")

plt.figure(figsize=(12, 4))
for i in range(min(10, len(preprocessed_images))):  # Hanya tampilkan max 10
    plt.subplot(2, 5, i + 1)
    plt.imshow(preprocessed_images[i])
    plt.title(f"{i+1}")
    plt.axis("off")
plt.tight_layout()
plt.show()

"""# DETEKSI FITUR"""

def detect_microaneurysms(img):
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (15, 15))
    tophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)
    _, thresh = cv2.threshold(tophat, 20, 255, cv2.THRESH_BINARY)
    return np.sum(thresh) > 500

def detect_hemorrhages(img):
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (25, 25))
    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)
    _, thresh = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)
    return np.sum(thresh) > 1000

def detect_exudates(img):
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    _, thresh = cv2.threshold(gray, 180, 255, cv2.THRESH_BINARY)
    return np.sum(thresh) > 3000

def detect_neovascularization(img):
    gray = cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)
    vessels = frangi(gray, sigmas=np.linspace(1, 10, 5))
    vessels = remove_small_objects(vessels > 0.05, min_size=15)  # lebih sensitif
    return np.sum(vessels) > 1000

# Detect features for all images
feature_results = []
for img in tqdm(preprocessed_images):
    ma = detect_microaneurysms(img)
    hem = detect_hemorrhages(img)
    ex = detect_exudates(img)
    neo = detect_neovascularization(img)
    features = {'Microaneurysms': ma, 'Hemorrhages': hem, 'Exudates': ex, 'Neovascularization': neo}
    feature_results.append(features)

# Infer severity based on features (for demonstration)
severity_classification = []
class_names = ['No_DR', 'Mild', 'Moderate', 'Severe', 'PDR']
for features in feature_results:
    if features['Neovascularization']:
        severity = 'PDR'
    elif features['Exudates'] and (features['Microaneurysms'] or features['Hemorrhages']):
        severity = 'Severe'
    elif features['Microaneurysms'] and features['Hemorrhages']:
        severity = 'Moderate'
    elif features['Microaneurysms']:
        severity = 'Mild'
    else:
        severity = 'No_DR'
    severity_classification.append(severity)

valid_labels = severity_classification

# Jumlah gambar yang ingin ditampilkan
n_display = min(5, len(preprocessed_images))

# Buat subplot horizontal
fig, axs = plt.subplots(1, n_display, figsize=(5 * n_display, 5))

for i in range(n_display):
    axs[i].imshow(preprocessed_images[i])
    axs[i].set_title(f"{severity_classification[i]}", fontsize=10)
    axs[i].axis('off')
    print(f"Image {i+1} ({valid_image_files[i]}):")
    print(f"Features: {feature_results[i]}")
    print(f"Inferred Severity: {severity_classification[i]}")

plt.suptitle("Deteksi Fitur & Klasifikasi Stadium Retinopati Diabetik", fontsize=14)
plt.tight_layout()
plt.show()

from collections import Counter

# Jika valid_labels berisi string label ('No_DR', 'Mild', dst)
class_counts = Counter(valid_labels)

print("Class distribution:")
for label, count in class_counts.items():
    print(f"{label}: {count}")

# Misalnya valid_labels berisi string label seperti 'Mild', 'Severe', dll
class_names = ['No_DR', 'Mild', 'Moderate', 'Severe', 'PDR']
class_counts = Counter(valid_labels)

# Ambil jumlah berdasarkan urutan class_names
counts = [class_counts.get(label, 0) for label in class_names]

# Visualisasi
plt.figure(figsize=(8,5))
plt.bar(class_names, counts, color='skyblue')
plt.title('Distribusi Kelas Retinopati Diabetik')
plt.xlabel('Kelas')
plt.ylabel('Jumlah Gambar')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# Daftar nama kelas dalam urutan yang konsisten
class_names = ['No_DR', 'Mild', 'Moderate', 'Severe', 'PDR']

# Buat mapping string ke integer dan sebaliknya
label_to_index = {name: idx for idx, name in enumerate(class_names)}
index_to_label = {idx: name for name, idx in label_to_index.items()}

# Jika valid_labels masih string, ubah ke integer
if isinstance(valid_labels[0], str):
    print("Mengonversi string labels ke integer...")
    valid_labels = np.array([label_to_index[label] for label in valid_labels])
else:
    valid_labels = np.array(valid_labels)  # pastikan array integer

# ✅ Cek hasil
print("Contoh label setelah konversi:", valid_labels[:5])
print("Class distribution:", {index_to_label[k]: v for k, v in Counter(valid_labels).items()})

import shutil

# Save preprocessed images into folders
for cls in class_names:
    os.makedirs(os.path.join(OUTPUT_DIR, cls), exist_ok=True)

for i, (img, label) in enumerate(zip(preprocessed_images, valid_labels)):
    cls_dir = os.path.join(OUTPUT_DIR, class_names[label])
    img_path = os.path.join(cls_dir, f"img_{i}.png")
    img_to_save = (img * 255).astype(np.uint8)
    cv2.imwrite(img_path, cv2.cvtColor(img_to_save, cv2.COLOR_RGB2BGR))

"""# JIKA DATA IMBALANCE PAKAI WCGAN"""

# CONFIG
IMG_SHAPE = (128, 128, 3)
NOISE_DIM = 100
NUM_CLASSES = 5
BATCH_SIZE = 32
EPOCHS = 200
N_CRITIC = 5
CLIP_VALUE = 0.01

def wasserstein_loss(y_true, y_pred):
    return tf.reduce_mean(y_true * y_pred)

def build_generator():
    noise = Input(shape=(NOISE_DIM,))
    label = Input(shape=(1,))
    label_embedding = Embedding(NUM_CLASSES, NOISE_DIM)(label)
    label_embedding = Flatten()(label_embedding)
    model_input = Concatenate()([noise, label_embedding])

    x = Dense(8 * 8 * 256)(model_input)
    x = BatchNormalization()(x)
    x = LeakyReLU(0.2)(x)
    x = Reshape((8, 8, 256))(x)

    x = Conv2DTranspose(128, (4, 4), strides=2, padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(0.2)(x)

    x = Conv2DTranspose(64, (4, 4), strides=2, padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(0.2)(x)

    x = Conv2DTranspose(32, (4, 4), strides=2, padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(0.2)(x)

    x = Conv2DTranspose(3, (4, 4), strides=2, padding='same', activation='tanh')(x)

    model = Model([noise, label], x)
    return model

def build_critic():
    img = Input(shape=IMG_SHAPE)
    label = Input(shape=(1,))
    label_embedding = Embedding(NUM_CLASSES, np.prod(IMG_SHAPE))(label)
    label_embedding = Flatten()(label_embedding)
    label_embedding = Reshape(IMG_SHAPE)(label_embedding)

    merged = Concatenate(axis=-1)([img, label_embedding])

    x = Conv2D(64, (4, 4), strides=2, padding='same')(merged)
    x = LeakyReLU(0.2)(x)

    x = Conv2D(128, (4, 4), strides=2, padding='same')(x)
    x = LeakyReLU(0.2)(x)

    x = Conv2D(256, (4, 4), strides=2, padding='same')(x)
    x = LeakyReLU(0.2)(x)

    x = Flatten()(x)
    x = Dense(1)(x)

    model = Model([img, label], x)
    return model

def train_generator_step(generator, critic, batch_size, noise_dim, class_label_batch):
    noise = tf.random.normal([batch_size, noise_dim])
    misleading_labels = -tf.ones((batch_size, 1))

    with tf.GradientTape() as tape:
        generated_images = generator([noise, class_label_batch], training=True)
        predictions = critic([generated_images, class_label_batch], training=True)
        g_loss = wasserstein_loss(misleading_labels, predictions)

    grads = tape.gradient(g_loss, generator.trainable_variables)
    generator.optimizer.apply_gradients(zip(grads, generator.trainable_variables))
    return g_loss

def train_wcgan(generator, critic, images, labels):
    gen_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00005)
    critic_optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00005)

    generator.optimizer = gen_optimizer
    critic.compile(optimizer=critic_optimizer, loss=wasserstein_loss)

    g_loss_log = []
    d_loss_log = []

    for epoch in range(EPOCHS):
        for _ in range(N_CRITIC):
            idx = np.random.randint(0, images.shape[0], BATCH_SIZE)
            real_imgs = images[idx]
            real_labels = tf.convert_to_tensor(labels[idx].astype(np.int32))

            noise = tf.random.normal((BATCH_SIZE, NOISE_DIM))
            fake_imgs = generator([noise, real_labels], training=False)

            d_loss_real = critic.train_on_batch([real_imgs, real_labels], -np.ones((BATCH_SIZE, 1)))
            d_loss_fake = critic.train_on_batch([fake_imgs, real_labels], np.ones((BATCH_SIZE, 1)))
            d_loss = 0.5 * (d_loss_real + d_loss_fake)
            d_loss_log.append(d_loss)

            for layer in critic.layers:
                weights = layer.get_weights()
                weights = [np.clip(w, -CLIP_VALUE, CLIP_VALUE) for w in weights]
                layer.set_weights(weights)

        g_loss = train_generator_step(generator, critic, BATCH_SIZE, NOISE_DIM, real_labels)
        g_loss_log.append(g_loss)

        if epoch % 100 == 0:
            print(f"Epoch {epoch} | D Loss: {d_loss:.4f} | G Loss: {g_loss:.4f}")

    return g_loss_log, d_loss_log

# ⚠️ Asumsikan: preprocessed_images → normalisasi [-1, 1], valid_labels → array of int class
class_counts = Counter(valid_labels)
minority_classes = [cls for cls, count in class_counts.items() if count < max(class_counts.values())]

generator = build_generator()
critic = build_critic()

g_loss_log_total, d_loss_log_total = [], []

for cls in minority_classes:
    print(f"\n🔁 Training WCGAN for class {cls}...")
    cls_mask = np.array(valid_labels) == cls
    cls_images = preprocessed_images[cls_mask]
    cls_labels = np.array(valid_labels)[cls_mask].reshape(-1, 1)

    # ✅ Train WCGAN dan ambil loss log
    g_log, d_log = train_wcgan(generator, critic, cls_images, cls_labels)
    g_loss_log_total.extend(g_log)
    d_loss_log_total.extend(d_log)

    # 🔧 Generate synthetic images
    synth_noise = np.random.normal(0, 1, (100, NOISE_DIM))
    synth_labels = np.full((100, 1), cls)
    synth_images = generator.predict([synth_noise, synth_labels], verbose=0)

    # Combine data asli dan sintetis
    preprocessed_images = np.concatenate([preprocessed_images, synth_images])
    valid_labels = np.concatenate([valid_labels, synth_labels.flatten()])

final_counts = Counter(valid_labels)
print("\n📊 New class distribution:")
for cls, count in final_counts.items():
    print(f"Class {cls}: {count}")

plt.figure(figsize=(10, 5))
plt.plot(g_loss_log_total, label='Generator Loss')
plt.plot(d_loss_log_total, label='Discriminator Loss')
plt.title("WCGAN Loss per Epoch (All Classes)")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.grid(True)
plt.show()

import cv2
from datetime import datetime

# Direktori untuk menyimpan gambar hasil augmentasi
AUGMENTED_DIR = './augmented_images'

# Save preprocessed images into folders
for cls in class_names:
    os.makedirs(os.path.join(AUGMENTED_DIR, cls), exist_ok=True)

for i, (img, label) in enumerate(zip(preprocessed_images, valid_labels)):
    cls_dir = os.path.join(AUGMENTED_DIR, class_names[label])
    img_path = os.path.join(cls_dir, f"gan_img_{i}.png")
    img_to_save = (img * 255).astype(np.uint8)
    cv2.imwrite(img_path, cv2.cvtColor(img_to_save, cv2.COLOR_RGB2BGR))

import shutil
from google.colab import files

# Kompres folder jadi zip
shutil.make_archive('augmented_images', 'zip', 'augmented_images')

# Download
files.download('augmented_images.zip')

import os
import numpy as np
import cv2
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras import layers, models

IMG_SIZE = 128
BATCH_SIZE = 32

def load_dataset_from_folder(folder_path):
    images = []
    labels = []
    class_names = sorted(os.listdir(folder_path))
    class_to_idx = {cls: i for i, cls in enumerate(class_names)}

    for cls in class_names:
        cls_folder = os.path.join(folder_path, cls)
        for img_name in os.listdir(cls_folder):
            img_path = os.path.join(cls_folder, img_name)
            img = cv2.imread(img_path)
            if img is not None:
                img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
                images.append(img)
                labels.append(class_to_idx[cls])

    return np.array(images), np.array(labels), class_names

def build_cnn_model(input_shape=(128, 128, 3), num_classes=5):
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D(2, 2),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D(2, 2),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D(2, 2),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(num_classes, activation='softmax')
    ])

    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

def train_and_evaluate_cnn(X, y, title=''):
    X = X.astype('float32') / 255.0
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

    model = build_cnn_model(input_shape=X.shape[1:], num_classes=len(np.unique(y)))
    model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=2)

    y_pred = np.argmax(model.predict(X_test), axis=1)

    print(f"\n📊 Classification Report ({title})")
    print(classification_report(y_test, y_pred))

    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y), yticklabels=np.unique(y))
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title(f"Confusion Matrix ({title})")
    plt.show()

    return model

     # Save model
    save_path = f"./model_{title.replace(' ', '_').lower()}.keras"
    model.save(save_path)
    print(f"💾 Model saved to: {save_path}\n")
    return model

print("🚀 Evaluasi CNN pada Dataset Augmentasi")
X_aug, y_aug, class_names = load_dataset_from_folder(AUGMENTED_DIR)
model_aug = train_and_evaluate_cnn(X_aug, y_aug, title='Augmented WCGAN')

# Simpan secara eksplisit (opsional, jika ingin override lokasi)
save_path = "/content/weights/model_augmented_wcgan.keras"
model_aug.save(save_path)